import streamlit as st
from openai import OpenAI
import json
import base64
import asyncio
import edge_tts
import os
import tempfile
from streamlit_mic_recorder import mic_recorder

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="AI è‹±è¯­å£è¯­ç§æ•™", layout="wide", initial_sidebar_state="collapsed")

# --- 2. CSS æ ·å¼ ---
st.markdown("""
    <style>
        .stApp { background-color: #F7F8FA; }
        .main .block-container { padding-bottom: 180px; max-width: 900px; }
        .phase-card {
            background-color: white; border-radius: 12px; padding: 20px;
            margin-bottom: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.03); border-left: 6px solid #CCC;
        }
        .phase-1 { border-left-color: #4A90E2; }
        .phase-2 { border-left-color: #50C878; background-color: #F0FFF4; }
        .phase-3 { border-left-color: #FF9F43; }
        .phase-header { font-weight: bold; font-size: 1.1rem; margin-bottom: 10px; color: #333; }
        .footer-container {
            position: fixed; bottom: 0; left: 0; right: 0;
            background: rgba(255, 255, 255, 0.98); backdrop-filter: blur(10px);
            padding: 20px 0; border-top: 1px solid #EEE; z-index: 1000;
        }
        /* ç´§å‡‘å‹éŸ³é¢‘æ¡æ ·å¼ */
        audio { height: 30px; width: 100%; margin-top: 8px; }
    </style>
""", unsafe_allow_html=True)

# --- 3. å¯†é’¥ä¸çŠ¶æ€åˆå§‹åŒ– ---
groq_api_key = st.secrets.get("GROQ_API_KEY", "")

if "messages" not in st.session_state: st.session_state.messages = []
if "last_played_id" not in st.session_state: st.session_state.last_played_id = None

# --- 4. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ’¡ æ•™ç»ƒè®¾ç½®")
    if not groq_api_key:
        groq_api_key = st.text_input("è¯·è¾“å…¥ Groq API Key", type="password")
    
    voice_choice = st.selectbox("å£éŸ³é€‰æ‹©", ["ç¾å¼å¥³å£° (Ava)", "è‹±å¼å¥³å£° (Sonia)", "ç¾å¼ç”·å£° (Andrew)"])
    v_map = {
        "ç¾å¼å¥³å£° (Ava)": "en-US-AvaMultilingualNeural", 
        "è‹±å¼å¥³å£° (Sonia)": "en-GB-SoniaNeural", 
        "ç¾å¼ç”·å£° (Andrew)": "en-US-AndrewMultilingualNeural"
    }
    input_mode = st.radio("å½•å…¥æ¨¡å¼", ["è¯­éŸ³", "æ–‡å­—"])
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²"):
        st.session_state.messages = []
        st.session_state.last_played_id = None
        st.rerun()

groq_client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=groq_api_key) if groq_api_key else None

# --- 5. æ ¸å¿ƒåŠŸèƒ½ ---
async def get_voice_audio(text, voice="en-US-AvaMultilingualNeural"):
    if not text or len(text.strip()) == 0: return ""
    communicate = edge_tts.Communicate(text, voice)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
        tmp_path = tmp.name
    await communicate.save(tmp_path)
    with open(tmp_path, "rb") as f: data = f.read()
    os.remove(tmp_path)
    return base64.b64encode(data).decode()

def get_ai_response(user_text):
    system_prompt = """
    ä½ ç°åœ¨æ‹¥æœ‰åŒé‡èº«ä»½ï¼Œè¯·ä¸¥æ ¼æŒ‰é¡ºåºæ‰§è¡Œï¼š
    1. ã€èº«ä»½ï¼šä¸“ä¸šå¯¼å¸ˆã€‘
       - phase1_correction: é’ˆå¯¹ç”¨æˆ·çš„æ–‡æœ¬çº é”™å’Œå‘éŸ³æŒ‡å¯¼ï¼ˆä¸­æ–‡ï¼‰ã€‚
       - phase2_optimized_text: æä¾›ä¸€ä¸ªæœ€åœ°é“çš„ä¼˜åŒ–ä¾‹å¥ï¼ˆè‹±æ–‡ï¼‰ã€‚
    2. ã€èº«ä»½ï¼šçŸ¥å¿ƒæœ‹å‹ã€‘
       - phase3_interaction: å¿˜æ‰è€å¸ˆèº«ä»½ï¼ç°åœ¨ä½ åœ¨å¹³ç­‰èŠå¤©ã€‚å…ˆå¯¹ç”¨æˆ·å†…å®¹ç»™äºˆçœŸè¯šçš„æƒ…æ„Ÿå›åº”ï¼ˆå¦‚ï¼šThat sounds great!ï¼‰ï¼Œåˆ†äº«ä¸€ç‚¹çœ‹æ³•ï¼Œæœ€åè‡ªç„¶åœ°æŠ›å‡ºä¸€ä¸ªè¿½é—®ã€‚
    3. phase4_expansion: æä¾› 2 å¥é’ˆå¯¹é˜¶æ®µ 3 çš„åº”ç­”å‚è€ƒï¼ˆ1 åŸºç¡€ï¼Œ1 è¿›é˜¶ï¼‰ã€‚
    è¯·ä»¥ JSON è¾“å‡ºã€‚
    """
    try:
        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_text}],
            response_format={"type": "json_object"},
            temperature=0.7
        )
        return json.loads(response.choices[0].message.content)
    except: return None

# --- 6. èŠå¤©åŒºæ¸²æŸ“ ---
st.title("ğŸ™ï¸ AI è‹±è¯­å£è¯­æ•™ç»ƒ")
if not groq_api_key:
    st.warning("ğŸ‘ˆ è¯·å…ˆé…ç½® API Key")
else:
    for i, msg in enumerate(st.session_state.messages):
        if msg["role"] == "user":
            with st.chat_message("user", avatar="ğŸ‘¤"): st.write(msg["content"])
        else:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                data = msg["content"]
                
                # --- é˜¶æ®µ 1: çº é”™ ---
                st.markdown(f'<div class="phase-card phase-1"><div class="phase-header">ğŸ”µ AI çº é”™ç‚¹è¯„</div>{data["phase1_correction"]}</div>', unsafe_allow_html=True)
                
                # --- é˜¶æ®µ 2: ä¼˜åŒ–è¡¨è¾¾ (æ‰‹åŠ¨æ’­æ”¾) ---
                st.markdown(f'<div class="phase-card phase-2"><div class="phase-header">ğŸŸ¢ AI ä¼˜åŒ–è¡¨è¾¾ (ç‚¹å‡»è·Ÿè¯»)</div><span style="font-size:1.2rem; color:#1B5E20;"><b>{data["phase2_optimized_text"]}</b></span>', unsafe_allow_html=True)
                # ç”Ÿæˆä¼˜åŒ–å¥éŸ³é¢‘ (æ°¸ä¸è‡ªåŠ¨æ’­æ”¾)
                opt_audio_b64 = asyncio.run(get_voice_audio(data["phase2_optimized_text"], v_map[voice_choice]))
                st.markdown(f'<audio src="data:audio/mp3;base64,{opt_audio_b64}" controls></audio></div>', unsafe_allow_html=True)
                
                # --- é˜¶æ®µ 3: äº’åŠ¨äº¤æµ (æœ€æ–°æ¶ˆæ¯è‡ªåŠ¨æ’­æ”¾) ---
                st.markdown(f'<div class="phase-card phase-3"><div class="phase-header">ğŸ’¬ Chatting with Friend</div>{data["phase3_interaction"]}', unsafe_allow_html=True)
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºæœ€æ–°æ¶ˆæ¯ä»¥å†³å®šæ˜¯å¦è‡ªåŠ¨æ’­æ”¾
                current_interact_id = hash(data["phase3_interaction"])
                is_new_interact = (i == len(st.session_state.messages) - 1) and (st.session_state.last_played_id != current_interact_id)
                
                inter_audio_b64 = asyncio.run(get_voice_audio(data["phase3_interaction"], v_map[voice_choice]))
                autoplay_attr = "autoplay" if is_new_interact else ""
                st.markdown(f'<audio src="data:audio/mp3;base64,{inter_audio_b64}" {autoplay_attr} controls></audio></div>', unsafe_allow_html=True)
                
                # è®°å½•å·²æ’­æ”¾
                if is_new_interact: st.session_state.last_played_id = current_interact_id
                
                # --- é˜¶æ®µ 4: å›åº”å‚è€ƒ ---
                st.markdown(f"<div style='padding-left:15px; margin-bottom:15px;'><small style='color:#888;'>ğŸ’¡ å›åº”å‚è€ƒ: 1ï¸âƒ£ {data['phase4_expansion'][0]} | 2ï¸âƒ£ {data['phase4_expansion'][1]}</small></div>", unsafe_allow_html=True)

# --- 7. åº•éƒ¨è¾“å…¥ ---
st.markdown('<div class="footer-container">', unsafe_allow_html=True)
cols = st.columns([1, 6, 1])
with cols[1]:
    if input_mode == "è¯­éŸ³":
        audio_in = mic_recorder(start_prompt="ğŸ¤ é•¿æŒ‰å¼€å§‹å½•éŸ³", stop_prompt="âœ… æ¾å¼€è¯†åˆ«", key='recorder', use_container_width=True)
        if audio_in:
            curr_hash = hash(audio_in['bytes'])
            if "last_audio_hash" not in st.session_state or st.session_state.last_audio_hash != curr_hash:
                st.session_state.last_audio_hash = curr_hash
                with st.spinner("æ€è€ƒä¸­..."):
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                        tmp.write(audio_in['bytes'])
                        t_path = tmp.name
                    with open(t_path, "rb") as f:
                        transcript = groq_client.audio.transcriptions.create(model="whisper-large-v3", file=f)
                    os.remove(t_path)
                    user_text = transcript.text
                    if user_text.strip():
                        ai_data = get_ai_response(user_text)
                        if ai_data:
                            st.session_state.messages.append({"role": "user", "content": user_text})
                            st.session_state.messages.append({"role": "assistant", "content": ai_data})
                            st.rerun()
    else:
        txt_in = st.chat_input("è¾“å…¥è‹±è¯­å¥å­...")
        if txt_in:
            with st.spinner("æ€è€ƒä¸­..."):
                ai_data = get_ai_response(txt_in)
                if ai_data:
                    st.session_state.messages.append({"role": "user", "content": txt_in})
                    st.session_state.messages.append({"role": "assistant", "content": ai_data})
                    st.rerun()
st.markdown('</div>', unsafe_allow_html=True)
