import streamlit as st
from openai import OpenAI
import json
import base64
import asyncio
import edge_tts
import os
import tempfile
from streamlit_mic_recorder import mic_recorder

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="AI è‹±è¯­å£è¯­ç§æ•™", layout="wide", initial_sidebar_state="collapsed")

# --- 2. CSS æ ·å¼ ---
st.markdown("""
    <style>
        .stApp { background-color: #F7F8FA; }
        .main .block-container { padding-bottom: 180px; max-width: 900px; }
        .phase-card {
            background-color: white; border-radius: 12px; padding: 20px;
            margin-bottom: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.03); border-left: 6px solid #CCC;
        }
        .phase-1 { border-left-color: #4A90E2; }
        .phase-2 { border-left-color: #50C878; background-color: #F0FFF4; }
        .phase-3 { border-left-color: #FF9F43; }
        .phase-header { font-weight: bold; font-size: 1.1rem; margin-bottom: 10px; color: #333; }
        .footer-container {
            position: fixed; bottom: 0; left: 0; right: 0;
            background: rgba(255, 255, 255, 0.98); backdrop-filter: blur(10px);
            padding: 20px 0; border-top: 1px solid #EEE; z-index: 1000;
        }
        audio { height: 35px; width: 100%; margin-top: 10px; }
    </style>
""", unsafe_allow_html=True)

# --- 3. å¯†é’¥ä¸çŠ¶æ€åˆå§‹åŒ– ---
groq_api_key = st.secrets.get("GROQ_API_KEY", "")

if "messages" not in st.session_state: st.session_state.messages = []
if "last_played_id" not in st.session_state: st.session_state.last_played_id = None

# --- 4. ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ’¡ æ•™ç»ƒè®¾ç½®")
    if not groq_api_key:
        groq_api_key = st.text_input("è¯·è¾“å…¥ Groq API Key", type="password")
    
    voice_choice = st.selectbox("å£éŸ³é€‰æ‹©", ["ç¾å¼å¥³å£° (Ava)", "è‹±å¼å¥³å£° (Sonia)", "ç¾å¼ç”·å£° (Andrew)"])
    v_map = {
        "ç¾å¼å¥³å£° (Ava)": "en-US-AvaMultilingualNeural", 
        "è‹±å¼å¥³å£° (Sonia)": "en-GB-SoniaNeural", 
        "ç¾å¼ç”·å£° (Andrew)": "en-US-AndrewMultilingualNeural"
    }
    input_mode = st.radio("å½•å…¥æ¨¡å¼", ["è¯­éŸ³", "æ–‡å­—"])
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²"):
        st.session_state.messages = []
        st.session_state.last_played_id = None
        st.rerun()

groq_client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=groq_api_key) if groq_api_key else None

# --- 5. æ ¸å¿ƒè¾…åŠ©åŠŸèƒ½ ---
async def get_voice_audio(text, voice="en-US-AvaMultilingualNeural"):
    if not text or len(text.strip()) == 0: return ""
    try:
        communicate = edge_tts.Communicate(text, voice)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
            tmp_path = tmp.name
        await communicate.save(tmp_path)
        with open(tmp_path, "rb") as f: data = f.read()
        os.remove(tmp_path)
        return base64.b64encode(data).decode()
    except: return ""

def get_ai_response(user_text):
    system_prompt = """
    ä½ ç°åœ¨æ‹¥æœ‰åŒé‡èº«ä»½ï¼Œè¯·ä¸¥æ ¼æŒ‰é¡ºåºæ‰§è¡Œå¹¶è¾“å‡º JSONï¼š
    1. ã€èº«ä»½ï¼šä¸“ä¸šå¯¼å¸ˆã€‘
       - phase1_correction: é’ˆå¯¹ç”¨æˆ·çš„æ–‡æœ¬çº é”™å’Œå‘éŸ³æŒ‡å¯¼ï¼ˆä¸­æ–‡ï¼‰ã€‚
       - phase2_optimized_text: æä¾›ä¸€ä¸ªæœ€åœ°é“çš„ä¼˜åŒ–å®Œæ•´ä¾‹å¥ï¼ˆè‹±æ–‡ï¼‰ã€‚
    2. ã€èº«ä»½ï¼šçŸ¥å¿ƒæœ‹å‹ã€‘
       - phase3_interaction: å¿˜æ‰è€å¸ˆèº«ä»½ï¼ç°åœ¨ä½ åœ¨å¹³ç­‰èŠå¤©ã€‚å…ˆå¯¹ç”¨æˆ·å†…å®¹ç»™äºˆçœŸè¯šçš„æƒ…æ„Ÿå›åº”ï¼ˆå¦‚ï¼šThat sounds great!ï¼‰ï¼Œåˆ†äº«ä¸€ç‚¹çœ‹æ³•ï¼Œæœ€åè‡ªç„¶åœ°æŠ›å‡ºä¸€ä¸ªè¿½é—®ã€‚
    3. phase4_expansion: æä¾› 2 å¥é’ˆå¯¹é˜¶æ®µ 3 çš„åº”ç­”å‚è€ƒï¼ˆå¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œå«2ä¸ªå­—ç¬¦ä¸²ï¼‰ã€‚
    
    æ³¨æ„ï¼šJSON å­—æ®µåå¿…é¡»ä¸¥æ ¼åŒ¹é…ï¼Œä¸è¦ç¼ºå¤±ã€‚
    """
    try:
        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_text}],
            response_format={"type": "json_object"},
            temperature=0.7
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        st.error(f"AI å“åº”è§£æå¤±è´¥: {e}")
        return None

# --- 6. èŠå¤©åŒºæ¸²æŸ“ ---
st.title("ğŸ™ï¸ AI è‹±è¯­å£è¯­æ•™ç»ƒ")

if not groq_api_key:
    st.warning("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§é…ç½® API Key")
else:
    for i, msg in enumerate(st.session_state.messages):
        if msg["role"] == "user":
            with st.chat_message("user", avatar="ğŸ‘¤"): st.write(msg["content"])
        else:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                data = msg["content"]
                
                # 1. çº é”™å±•ç¤º
                p1 = data.get("phase1_correction", "æš‚æ— ç‚¹è¯„")
                st.markdown(f'<div class="phase-card phase-1"><div class="phase-header">ğŸ”µ AI çº é”™ç‚¹è¯„</div>{p1}</div>', unsafe_allow_html=True)
                
                # 2. ä¼˜åŒ–è¡¨è¾¾ (æ‰‹åŠ¨æ’­æ”¾)
                p2 = data.get("phase2_optimized_text", "")
                if p2:
                    st.markdown(f'<div class="phase-card phase-2"><div class="phase-header">ğŸŸ¢ AI ä¼˜åŒ–è¡¨è¾¾ (ç‚¹å‡»è·Ÿè¯»)</div><span style="font-size:1.2rem; color:#1B5E20;"><b>{p2}</b></span>', unsafe_allow_html=True)
                    opt_audio = asyncio.run(get_voice_audio(p2, v_map[voice_choice]))
                    if opt_audio:
                        st.markdown(f'<audio src="data:audio/mp3;base64,{opt_audio}" controls></audio></div>', unsafe_allow_html=True)
                    else: st.markdown('</div>', unsafe_allow_html=True)

                # 3. äº’åŠ¨äº¤æµ (è‡ªåŠ¨æ’­æ”¾)
                p3 = data.get("phase3_interaction", "Nice talking to you!")
                st.markdown(f'<div class="phase-card phase-3"><div class="phase-header">ğŸ’¬ Chatting with Friend</div>{p3}', unsafe_allow_html=True)
                
                inter_audio = asyncio.run(get_voice_audio(p3, v_map[voice_choice]))
                if inter_audio:
                    curr_id = hash(p3)
                    is_new = (i == len(st.session_state.messages) - 1) and (st.session_state.last_played_id != curr_id)
                    autoplay = "autoplay" if is_new else ""
                    st.markdown(f'<audio src="data:audio/mp3;base64,{inter_audio}" {autoplay} controls></audio></div>', unsafe_allow_html=True)
                    if is_new: st.session_state.last_played_id = curr_id
                else: st.markdown('</div>', unsafe_allow_html=True)

                # 4. æ‰©å±•å‚è€ƒ (é˜²å¾¡æ€§è¯»å–)
                p4 = data.get("phase4_expansion", [])
                if isinstance(p4, list) and len(p4) > 0:
                    tips = " | ".join([f"{idx+1}ï¸âƒ£ {text}" for idx, text in enumerate(p4)])
                    st.markdown(f"<div style='padding-left:15px; margin-bottom:15px;'><small style='color:#888;'>ğŸ’¡ å›åº”å‚è€ƒ: {tips}</small></div>", unsafe_allow_html=True)

# --- 7. åº•éƒ¨è¾“å…¥ ---
st.markdown('<div class="footer-container">', unsafe_allow_html=True)
cols = st.columns([1, 6, 1])
with cols[1]:
    if input_mode == "è¯­éŸ³":
        audio_in = mic_recorder(start_prompt="ğŸ¤ é•¿æŒ‰å¼€å§‹å½•éŸ³", stop_prompt="âœ… æ¾å¼€å‘é€", key='recorder', use_container_width=True)
        if audio_in:
            curr_hash = hash(audio_in['bytes'])
            if "last_audio_hash" not in st.session_state or st.session_state.last_audio_hash != curr_hash:
                st.session_state.last_audio_hash = curr_hash
                with st.spinner("æ•™ç»ƒæ­£åœ¨å¬..."):
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                        tmp.write(audio_in['bytes'])
                        t_path = tmp.name
                    with open(t_path, "rb") as f:
                        transcript = groq_client.audio.transcriptions.create(model="whisper-large-v3", file=f)
                    os.remove(t_path)
                    user_text = transcript.text
                    if user_text.strip():
                        ai_data = get_ai_response(user_text)
                        if ai_data:
                            st.session_state.messages.append({"role": "user", "content": user_text})
                            st.session_state.messages.append({"role": "assistant", "content": ai_data})
                            st.rerun()
    else:
        txt_in = st.chat_input("è¾“å…¥è‹±è¯­å¥å­...")
        if txt_in:
            with st.spinner("æ€è€ƒä¸­..."):
                ai_data = get_ai_response(txt_in)
                if ai_data:
                    st.session_state.messages.append({"role": "user", "content": txt_in})
                    st.session_state.messages.append({"role": "assistant", "content": ai_data})
                    st.rerun()
st.markdown('</div>', unsafe_allow_html=True)
